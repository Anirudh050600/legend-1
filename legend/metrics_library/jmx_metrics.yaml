component: jmx
data_source: Prometheus
reference: https://github.com/prometheus/jmx_exporter
description: JMX metrics
identifierKeys:
  - job
panels:
  - title: (U) Heap Utilized
    type: Graph
    description: Heap utilized percentage for each instance
    targets:
      {% for dimension in data %}
      - metric: sum by (instance) ((jvm_memory_bytes_used{job=~"{{ dimension.job }}",area="heap"})*100)/(sum by (instance) (jvm_memory_bytes_max{job=~"{{ dimension.job }}",area="heap"}))
        legend: '{{ '{{instance}}' }}'
        ref_no: 1
      {% endfor %}
    labelY1: Utilization
    formatY1: percent
    alert_config:
      priority: P3
      message: 'Heap Memory is High'
      rule:
        for_duration: 10m
        evaluate_every: 1m
      condition_query:
        - OR,avg,1,now,5m,gt,90

  - title: (U) Total Memory Utilization
    type: Graph
    description: Total Memory Utilization percentage for each instance
    targets:
      {% for dimension in data %}
      - metric: sum by (instance) ((jvm_memory_bytes_used{job=~"{{ dimension.job }}"})*100)/(sum by (instance) (java_lang_OperatingSystem_TotalPhysicalMemorySize{job=~"{{ dimension.job }}"}))
        legend: '{{ '{{instance}}' }}'
        ref_no: 1
      {% endfor %}
    labelY1: Utilization
    formatY1: percent
    alert_config:
      priority: P3
      message: 'Total Memory Utilization is High'
      rule:
        for_duration: 10m
        evaluate_every: 1m
      condition_query:
        - OR,avg,1,now,5m,gt,90

  - title: (U) User Threads Count
    type: Graph
    description: (current - daemon) = user threads, MAX(peak count of active threads in the system from JVM start)
    targets:
      {% for dimension in data %}
      - metric: max(jvm_threads_peak{job="{{ dimension.job }}"})
        legend: MAX_PEAK
      - metric: jvm_threads_current{job="{{ dimension.job }}"} - jvm_threads_daemon{job="{{ dimension.job }}"}
        legend: '{{ '{{instance}}' }}'
      {% endfor %}

  - title: (U) Daemon Threads Count
    type: Graph
    description: Threads that are running in the background like GC etc..
    targets:
      {% for dimension in data %}
      - metric: jvm_threads_daemon{job="{{ dimension.job }}"}
        legend: '{{ '{{instance}}' }}'
      {% endfor %}

  - title: (S) File Descriptors Count
    type: Graph
    description: Maximum number of open file descriptors and Number of open file descriptors. https://docs.gigaspaces.com/latest/production/production-file-descriptors.html https://github.com/netdata/netdata/issues/1272
    targets:
      {% for dimension in data %}
      - metric: min(process_max_fds{job="{{ dimension.job }}"})
        legend: Max_File_descriptors
      - metric: process_open_fds{job="{{ dimension.job }}"}
        legend: '{{ '{{instance}}' }}'
      {% endfor %}


  - title: (S) File Descriptors Percentage
    type: Graph
    description: open file descriptors Percentage
    targets:
      {% for dimension in data %}
      - metric: sum by (instance) ((process_open_fds{job="{{ dimension.job }}"})*100)/(sum by (instance) (process_max_fds{job="{{ dimension.job }}"}))
        legend: '{{ '{{instance}}' }}'
        ref_no: 1
      {% endfor %}
    labelY1: Utilization
    formatY1: percent
    alert_config:
      priority: P3
      message: 'File Descriptors Percentage is High'
      rule:
        for_duration: 10m
        evaluate_every: 1m
      condition_query:
        - OR,avg,1,now,5m,gt,10

  - title: (E) DeadLock Threads Count
    type: Graph
    description:
    targets:
      {% for dimension in data %}
      - metric: jvm_threads_deadlocked{job="{{ dimension.job }}"}
        legend: '{{ '{{instance}}' }}'
      {% endfor %}
